{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AS - TME7\n",
    "2018--2019\n",
    "\n",
    "---\n",
    "\n",
    "Binome : Juliette Ortholand, Stieban Fernandez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèles de séquence (réccurents)\n",
    "- Modèle sur les caractères (prédire classe)\n",
    "- Modèle génératif\n",
    "\n",
    "Données Page AS@DAC\n",
    "-> names (classes) :\n",
    "- english.txt\n",
    "- french.txt\n",
    "- italian.txt\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque caractère en 1-hot -> char-embedding\n",
    "\n",
    "Etat précédent : s0 s1, s2, ... application d'une fonction f\n",
    "\n",
    "+\n",
    "\n",
    "Classifieur\n",
    "\n",
    "On travaille avec des batchs\n",
    "\n",
    "-> remplir caractère vide par 0 par ex\n",
    "\n",
    "---\n",
    "\n",
    "Pour les modèles génératifs : longueur du prénom + 1 caractère pour déterminer la fin de la chaine :\n",
    "\n",
    "Appliquer un masque : 1 s'il y a un caractère (+ caractère de fin) sinon 0\n",
    "\n",
    "-> Prédire à chaque fois l'état (/caractère) suivant.\n",
    "\n",
    "Utilisation : \n",
    "- Est-ce que \"Pierre\" est un prénom anglais ? (Calcul de la vraisemblance)\n",
    "- Générer des prénoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Parcourir les fichiers du répértoire avec glob('*.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from unidecode import unidecode\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "#-------------------------------------------------------\n",
    "# Extraction des noms et labels\n",
    "#-------------------------------------------------------\n",
    "gen = Path(\"data/names\").glob(\"*.txt\")\n",
    "\n",
    "L = [] # [(nom, pays), ...]\n",
    "D = {} # {label(int): pays, ...}\n",
    "for label, file in enumerate(gen):\n",
    "    D[label] = file.stem\n",
    "    \n",
    "    with open(str(file), \"r\", encoding=\"utf-8\") as f:\n",
    "        names = f.read().split(\"\\n\")[:-1]\n",
    "    for name in names:\n",
    "        # Nettoyage\n",
    "        name = \"\".join([c for c in unidecode(name.lower()) if c.isalpha()])\n",
    "        L.append((name, label))\n",
    "L = L[:500]\n",
    "#-------------------------------------------------------\n",
    "# Encodage\n",
    "#-------------------------------------------------------\n",
    "N = 27 # nombre de caractères différents pour le one hot\n",
    "\n",
    "code_char = lambda x: ord(x)-96\n",
    "\n",
    "decode_char = lambda x: chr(x+96)\n",
    "\n",
    "def encode_name(name, N, M=None):\n",
    "    # N : taille d'un vecteur one hot\n",
    "    # M : padding\n",
    "    res = torch.zeros((M if M!=None and M>len(name) else len(name)))\n",
    "    #res = torch.zeros((M if M!=None and M>len(name) else len(name)), N)\n",
    "    for i, c in enumerate(name):\n",
    "        res[i] = code_char(c)\n",
    "        #res[i, code_char(c)] = 1\n",
    "    res[len(name):] = 1\n",
    "    #res[len(name):, 0] = 1\n",
    "    return res\n",
    "\n",
    "def decode_name(indxs):\n",
    "    return \"\".join([decode_char(indx) for indx in indxs if indx!=1])\n",
    "    #return \"\".join([decode_char(indx.argmax()) for indx in indxs if indx[0]!=1])\n",
    "\n",
    "#-------------------------------------------------------\n",
    "# Construction du DataSet \n",
    "#-------------------------------------------------------\n",
    "class NameDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        name, label = self.data[index]\n",
    "        return encode_name(name, N), int(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "#-------------------------------------------------------\n",
    "# DataLoader\n",
    "#-------------------------------------------------------\n",
    "\n",
    "def collate_fn(sequences):\n",
    "    length = max([len(x[0]) for x in sequences])\n",
    "    data = torch.zeros(len(sequences), length)\n",
    "    #data = torch.zeros(len(sequences), length, N)\n",
    "    target = torch.zeros(len(sequences))\n",
    "    for i, (name, label) in enumerate(sequences):\n",
    "        data[i, :len(name)] = name\n",
    "        #data[i, len(name):, 0] = 1 # padding pour s'adapter aux dimensions du batch\n",
    "        data[i, len(name):] = 1\n",
    "        target[i] = label\n",
    "    return data, target\n",
    "        \n",
    "    \n",
    "def get_data_loader(dataset, batch_size):\n",
    "    return DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, \\\n",
    "                         collate_fn=collate_fn)\n",
    "\n",
    "#-------------------------------------------------------\n",
    "# Split Train Val\n",
    "#-------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = np.array(L).T\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y)\n",
    "\n",
    "train_set = NameDataset(np.vstack((Xtrain, ytrain)).T)\n",
    "val_set = NameDataset(np.vstack((Xval, yval)).T)\n",
    "\n",
    "train_iter = get_data_loader(train_set, 150)\n",
    "val_iter = get_data_loader(val_set, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16.,  9.,  5., 18., 18.,  5.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_name(\"pierre\", N, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 8]) torch.Size([150])\n",
      "torch.Size([150, 8]) torch.Size([150])\n",
      "torch.Size([75, 8]) torch.Size([75])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_iter:\n",
    "    ex, lab = x, y\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.emb = nn.Embedding(28,input_size)\n",
    "        \n",
    "        self.linx = nn.Linear(input_size, hidden_size)\n",
    "        self.linh = nn.Linear(hidden_size, hidden_size)\n",
    "        self.activ = nn.ReLU()\n",
    "        self.liny = nn.Linear(hidden_size, 28)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        # seq : (seq_length, batch_size)\n",
    "        \n",
    "        emb_seq = self.emb(seq)\n",
    "        output = self.initHidden()\n",
    "        \n",
    "        for _input in emb_seq:\n",
    "            output = self.activ(self.linx(_input) + self.linh(output))\n",
    "        output = self.liny(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "input_size, hidden_size, output_size = 50, 110, len(D)\n",
    "model = RNN(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-38c2b773816c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# TEST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ex' is not defined"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "out = model(ex.transpose(0,1).long())\n",
    "\n",
    "for i, e in enumerate(out):\n",
    "    print(decode_name(ex[i]), \":\", D[e.argmax().item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-ab99a4267936>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x.transpose(0,1).long().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,inputsize,hidden_size,output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        #Couches\n",
    "        self.linF = [nn.Linear(inputsize, hidden_size),nn.Linear(hidden_size, hidden_size)]\n",
    "        self.linI = [nn.Linear(inputsize, hidden_size),nn.Linear(hidden_size, hidden_size)]\n",
    "        self.linC = [nn.Linear(inputsize, hidden_size),nn.Linear(hidden_size, hidden_size)]\n",
    "        self.linO = [nn.Linear(inputsize, hidden_size),nn.Linear(hidden_size, hidden_size)]\n",
    "        self.linOp = nn.Linear(hidden_size, hidden_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        \n",
    "        self.clas = nn.Linear(hidden_size, output_size)\n",
    "        #Variables\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def forward(self, X):\n",
    "        c, h = self.initHidden()\n",
    "        for _input in X:            \n",
    "            #Bloc 1\n",
    "            tmp2 = self.sigmoid(self.linF[1](h)+self.linF[0](_input))\n",
    "            \n",
    "            #Bloc 2\n",
    "            tmp3 = self.sigmoid(self.linI[1](h)+self.linI[0](_input)) \\\n",
    "                    * self.tanh(self.linC[1](h)+self.linC[0](_input))\n",
    "            \n",
    "            #Application\n",
    "            c = (c * tmp2)+ tmp3\n",
    "            \n",
    "            #Bloc 3 \n",
    "            h = self.sigmoid(self.linO[1](h)+self.linO[0](_input)) * self.tanh(self.linOp(c))\n",
    "        \n",
    "        out = self.clas(h)                                     \n",
    "                                                          \n",
    "        return out\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size),torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "    \n",
    "    def score(self,ypred,y):\n",
    "        score = 0\n",
    "        if len(y) != len(ypred):\n",
    "            print('ERREUR')\n",
    "        for i in range(0,len(y)):\n",
    "            if y[i] == ypred[i].argmax():\n",
    "                score += 1\n",
    "        return(score/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_size, hidden_size, output_size)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "n_epochs = 2\n",
    "\n",
    "def accuracy(ypred, y):\n",
    "    ### Calcul du score\n",
    "    return (ypred.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "def fit_eval_rnn(model, loss, optim, train_iter, val_iter, n_epochs):\n",
    "    train_loss = []\n",
    "    train_score = []\n",
    "    val_loss = []\n",
    "    val_score = []\n",
    "\n",
    "    ### APPRENTISSAGE\n",
    "    #--------------------------------------------------------\n",
    "    for i in range(n_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        ####### TRAIN #######\n",
    "        costs_train = []\n",
    "        scores_train = []\n",
    "        for x, l in train_iter:\n",
    "            x = x.transpose(0,1).long()\n",
    "            for i in range(0,len(x)-1):\n",
    "                x_seq = x[:i+1]\n",
    "                y_seq = x[i:i+1].view(-1)\n",
    "\n",
    "                out = model(x_seq)\n",
    "                cost = loss(out, y_seq)\n",
    "                optim.zero_grad()\n",
    "                cost.backward()\n",
    "                optim.step()\n",
    "\n",
    "                costs_train.append(cost.float())\n",
    "                scores_train.append(float(accuracy(out, y_seq)))\n",
    "\n",
    "            train_loss.append(torch.tensor(costs_train).float().mean())\n",
    "            train_score.append(torch.tensor(scores_train).float().mean())\n",
    "\n",
    "        model.eval()\n",
    "        ####### VALID #######\n",
    "        costs_val = []\n",
    "        scores_val = []\n",
    "        for x, l in val_iter:\n",
    "            x = x.transpose(0,1).long()\n",
    "            for i in range(0,len(x)-1):\n",
    "                x_seq = x[:i+1]\n",
    "                y_seq = x[i:i+1].view(-1)\n",
    "                \n",
    "                out = model(x_seq)\n",
    "                cost = loss(out, y_seq)\n",
    "\n",
    "                costs_val.append(cost.float())\n",
    "                scores_val.append(float(accuracy(out, y_seq)))\n",
    "\n",
    "            val_loss.append(torch.tensor(costs_val).float().mean())\n",
    "            val_score.append(torch.tensor(scores_val).mean())\n",
    "        \n",
    "    return train_loss, val_loss, train_score, val_score\n",
    "\n",
    "\n",
    "def show_loss_score(train_loss, val_loss, train_score, val_score):\n",
    "    ### AFFICHAGE LOSS ET SCORE\n",
    "    #--------------------------------------------------------\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.plot(train_loss, c=\"red\", label=\"train\")\n",
    "    plt.plot(val_loss, c=\"b\", label=\"val\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title('Loss')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.plot(train_score, c=\"red\", label=\"train\")\n",
    "    plt.plot(val_score, c=\"b\", label=\"val\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title('score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.LongTensor but found type torch.FloatTensor for argument #2 'mat2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-eb4da65f9fcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_eval_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mshow_loss_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-152-5fe2ac9082d5>\u001b[0m in \u001b[0;36mfit_eval_rnn\u001b[1;34m(model, loss, optim, train_iter, val_iter, n_epochs)\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0my_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-151-642db956b692>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_input\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;31m#Bloc 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mtmp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m#Bloc 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1024\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of type torch.LongTensor but found type torch.FloatTensor for argument #2 'mat2'"
     ]
    }
   ],
   "source": [
    "res = fit_eval_rnn(model, loss, optim, train_iter, val_iter, n_epochs)\n",
    "show_loss_score(*res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'0': 500})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "collections.Counter(list(ytrain)+list(yval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultat biaisé car certaines classes contiennent plus d'exemples que d'autres\n",
    "\n",
    "--> Preprocessing nécessaire : rebalancage des classes pour l'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'robb'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = encode_name(\"robbin\", N, 19)\n",
    "decode_name(test[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model(test[:4].long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_name(res.argmax().view(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
